{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "195ac55a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# sir's exact sequence setup\n",
    "import os, warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import joblib\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split, learning_curve, GridSearchCV, cross_val_score\n",
    "from sklearn.preprocessing import LabelEncoder, label_binarize, StandardScaler\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix, roc_curve, auc, ConfusionMatrixDisplay, precision_recall_fscore_support\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, VotingClassifier, StackingClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "try:\n",
    "    from xgboost import XGBClassifier\n",
    "    HAS_XGB = True\n",
    "except Exception:\n",
    "    HAS_XGB = False\n",
    "\n",
    "try:\n",
    "    import shap\n",
    "    HAS_SHAP = True\n",
    "except Exception:\n",
    "    HAS_SHAP = False\n",
    "\n",
    "RANDOM_STATE = 42\n",
    "TEST_SIZE = 0.2\n",
    "TOP_K = 3\n",
    "MODEL_DIR = 'models'\n",
    "os.makedirs(MODEL_DIR, exist_ok=True)\n",
    "print('config ready. HAS_XGB=', HAS_XGB, 'HAS_SHAP=', HAS_SHAP)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3676b2c",
   "metadata": {},
   "source": [
    "# disease prediction pipeline (new dataset)\n",
    "this notebook follows your preferred structure and will use the extracted dataset from `data/dataset/`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4362cd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. imports and configuration\n",
    "import os, warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import joblib\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split, learning_curve\n",
    "from sklearn.preprocessing import LabelEncoder, label_binarize, StandardScaler\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix, roc_curve, auc\n",
    "from sklearn.metrics import ConfusionMatrixDisplay\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, VotingClassifier, StackingClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "try:\n",
    "    from xgboost import XGBClassifier\n",
    "    HAS_XGB = True\n",
    "except Exception:\n",
    "    HAS_XGB = False\n",
    "\n",
    "try:\n",
    "    import shap\n",
    "    HAS_SHAP = True\n",
    "except Exception:\n",
    "    HAS_SHAP = False\n",
    "\n",
    "RANDOM_STATE = 42\n",
    "TEST_SIZE = 0.2\n",
    "TOP_K = 3\n",
    "MODEL_DIR = 'models'\n",
    "os.makedirs(MODEL_DIR, exist_ok=True)\n",
    "print('config ready. HAS_XGB=', HAS_XGB, 'HAS_SHAP=', HAS_SHAP)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95a4096c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. dataset loading (guarded defaults)\n",
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "print('looking for files in project root:', os.listdir('.')[:10])\n",
    "\n",
    "if 'DATA_TRAIN' not in globals() or not isinstance(DATA_TRAIN, str):\n",
    "    DATA_TRAIN = os.path.join('data', 'dataset', 'trainings.csv')\n",
    "\n",
    "if not os.path.exists(DATA_TRAIN):\n",
    "    alt_path = os.path.join('data', 'dataset', 'trainings.csv')\n",
    "    if os.path.exists(alt_path):\n",
    "        DATA_TRAIN = alt_path\n",
    "\n",
    "assert os.path.exists(DATA_TRAIN), f'{DATA_TRAIN} not found'\n",
    "\n",
    "try:\n",
    "    df = pd.read_csv(DATA_TRAIN)\n",
    "except UnicodeDecodeError:\n",
    "    df = pd.read_csv(DATA_TRAIN, encoding='latin1')\n",
    "\n",
    "print('trainings.csv shape:', df.shape)\n",
    "print('columns:', list(df.columns)[:10], '...')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64db6909",
   "metadata": {},
   "outputs": [],
   "source": [
    "# debug: inspect columns tail and potential target\n",
    "print('last 10 columns:', list(df.columns[-10:]))\n",
    "for cand in [df.columns[-1], 'Disease', 'prognosis', 'target', 'label']:\n",
    "    if cand in df.columns:\n",
    "        print('candidate target:', cand, 'unique values:', df[cand].nunique())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "047e73e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4. basic data cleaning & inspection\n",
    "from IPython.display import display\n",
    "\n",
    "display(df.head())\n",
    "unnamed = [c for c in df.columns if str(c).lower().startswith('unnamed')]\n",
    "if unnamed:\n",
    "    df = df.drop(columns=unnamed)\n",
    "    print('dropped unnamed columns:', unnamed)\n",
    "else:\n",
    "    print('no unnamed columns to drop')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05b8cb95",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5. preprocessing to build X_proc and y_enc\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "target_col = df.columns[-1]\n",
    "X = df.drop(columns=[target_col]).copy()\n",
    "y = df[target_col].astype(str).copy()\n",
    "\n",
    "def to_numeric_col(series):\n",
    "    if series.dtype == 'object':\n",
    "        s = series.astype(str).str.strip().str.lower()\n",
    "        mapping = {'yes': 1, 'no': 0, 'true': 1, 'false': 0, 'nan': np.nan, 'none': np.nan, '': np.nan}\n",
    "        s = s.map(mapping).where(~s.isna(), other=np.nan)\n",
    "        s = pd.to_numeric(s, errors='coerce')\n",
    "        return s\n",
    "    else:\n",
    "        return pd.to_numeric(series, errors='coerce')\n",
    "\n",
    "X_proc = X.apply(to_numeric_col)\n",
    "X_proc = X_proc.fillna(0).astype(float)\n",
    "\n",
    "label_encoder_y = LabelEncoder()\n",
    "y_enc = label_encoder_y.fit_transform(y)\n",
    "\n",
    "print('X_proc shape:', X_proc.shape, 'y_enc shape:', y_enc.shape)\n",
    "print('num classes:', len(label_encoder_y.classes_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a487f5c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "\n",
    "class_counts = np.bincount(y_enc)\n",
    "use_stratify = np.min(class_counts) >= 2\n",
    "strat = y_enc if use_stratify else None\n",
    "if not use_stratify:\n",
    "    print('warning: disabling stratify due to rare classes (min count < 2)')\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X_proc, y_enc, test_size=TEST_SIZE, stratify=strat, random_state=RANDOM_STATE\n",
    ")\n",
    "print('train:', X_train.shape, 'test:', X_test.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4d7b714",
   "metadata": {},
   "outputs": [],
   "source": [
    "class_counts = np.bincount(y_enc)\n",
    "if (class_counts < 2).any():\n",
    "    print('note: at least one class has only 1 sample; disabling stratify for train/test split')\n",
    "    stratify_var = None\n",
    "else:\n",
    "    stratify_var = y_enc\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X_proc, y_enc, test_size=TEST_SIZE, stratify=stratify_var, random_state=RANDOM_STATE\n",
    ")\n",
    "print('train:', X_train.shape, 'test:', X_test.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57446bc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "dt = DecisionTreeClassifier(random_state=RANDOM_STATE)\n",
    "rf = RandomForestClassifier(n_estimators=200, random_state=RANDOM_STATE, n_jobs=-1)\n",
    "svm = SVC(kernel='rbf', probability=True, random_state=RANDOM_STATE)\n",
    "xgb = XGBClassifier(n_estimators=200, eval_metric='mlogloss', random_state=RANDOM_STATE) if HAS_XGB else None\n",
    "print('models ready. xgb available:', xgb is not None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "947fbb8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "rf = RandomForestClassifier(n_estimators=200, random_state=RANDOM_STATE, n_jobs=-1)\n",
    "svm = SVC(probability=True, random_state=RANDOM_STATE)\n",
    "dt = DecisionTreeClassifier(random_state=RANDOM_STATE)\n",
    "rf.fit(X_train, y_train)\n",
    "svm.fit(X_train, y_train)\n",
    "if 'xgb' in globals() and xgb is not None:\n",
    "    try:\n",
    "        xgb.fit(X_train, y_train)\n",
    "    except Exception as e:\n",
    "        print('xgb training skipped:', e)\n",
    "print('base models trained')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bb445ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_base = rf.predict(X_test)\n",
    "acc_base = accuracy_score(y_test, y_pred_base)\n",
    "f1_base = f1_score(y_test, y_pred_base, average='macro', zero_division=0)\n",
    "print(f'baseline RF accuracy: {acc_base:.4f}, macro F1: {f1_base:.4f}')\n",
    "cr = classification_report(y_test, y_pred_base, zero_division=0)\n",
    "print(cr[:1000])\n",
    "cm_base = confusion_matrix(y_test, y_pred_base)\n",
    "print('confusion matrix shape:', cm_base.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de8fde62",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('voting accuracy:', accuracy_score(y_test, y_vote))\n",
    "print(classification_report(y_test, y_vote, zero_division=0)[:1000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cfc1004",
   "metadata": {},
   "outputs": [],
   "source": [
    "class_counts_train = np.bincount(y_train)\n",
    "if (class_counts_train < 2).any():\n",
    "    print('stacking skipped: classes with <2 samples make CV invalid')\n",
    "else:\n",
    "    base_estimators = [('rf', rf), ('dt', dt)]\n",
    "    if 'xgb' in globals() and xgb is not None:\n",
    "        base_estimators.append(('xgb', xgb))\n",
    "    cv = StratifiedKFold(n_splits=3, shuffle=True, random_state=RANDOM_STATE)\n",
    "    stack = StackingClassifier(estimators=base_estimators, final_estimator=LogisticRegression(max_iter=1000), cv=cv, n_jobs=-1)\n",
    "    stack.fit(X_train, y_train)\n",
    "    y_stack = stack.predict(X_test)\n",
    "    print('stacking accuracy:', accuracy_score(y_test, y_stack))\n",
    "    print(classification_report(y_test, y_stack, zero_division=0)[:1000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7213abb",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "def plot_learning_curve_model(model, X, y, title=None):\n",
    "    if title is None:\n",
    "        title = f'learning curve ({type(model).__name__})'\n",
    "    train_sizes, train_scores, test_scores = learning_curve(model, X, y, cv=5, scoring='accuracy', train_sizes=np.linspace(0.1, 1.0, 5), n_jobs=-1)\n",
    "    train_mean = np.mean(train_scores, axis=1)\n",
    "    test_mean = np.mean(test_scores, axis=1)\n",
    "    plt.figure(figsize=(8,5))\n",
    "    plt.plot(train_sizes, train_mean, label='training score')\n",
    "    plt.plot(train_sizes, test_mean, label='validation score')\n",
    "    plt.xlabel('training examples')\n",
    "    plt.ylabel('accuracy')\n",
    "    plt.title(title)\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "    plt.show()\n",
    "\n",
    "def plot_confusion_matrix_model(model, X_test, y_test, title=None):\n",
    "    y_pred = model.predict(X_test)\n",
    "    cm = confusion_matrix(y_test, y_pred)\n",
    "    disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=le.classes_)\n",
    "    plt.figure(figsize=(8,6))\n",
    "    disp.plot(values_format='d', ax=plt.gca())\n",
    "    if title:\n",
    "        plt.title(title)\n",
    "    plt.show()\n",
    "\n",
    "def plot_multiclass_roc_model(model, X_test, y_test, title=None):\n",
    "    classes = np.unique(y_test)\n",
    "    n_classes = len(classes)\n",
    "    y_test_b = label_binarize(y_test, classes=classes)\n",
    "    if hasattr(model, 'predict_proba'):\n",
    "        y_score = model.predict_proba(X_test)\n",
    "    else:\n",
    "        y_score = model.decision_function(X_test)\n",
    "    plt.figure(figsize=(8,6))\n",
    "    for i in range(n_classes):\n",
    "        fpr, tpr, _ = roc_curve(y_test_b[:, i], y_score[:, i])\n",
    "        roc_auc = auc(fpr, tpr)\n",
    "        plt.plot(fpr, tpr, lw=2, label=f'{le.classes_[i]} (auc = {roc_auc:.2f})')\n",
    "    plt.plot([0,1],[0,1],'k--')\n",
    "    plt.xlabel('false positive rate')\n",
    "    plt.ylabel('true positive rate')\n",
    "    plt.title(title or f'multiclass roc (one-vs-rest) - {type(model).__name__}')\n",
    "    plt.legend(loc='lower right', fontsize='small')\n",
    "    plt.grid(True)\n",
    "    plt.show()\n",
    "\n",
    "print('plot utilities ready')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5dfa8a06",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import KFold, cross_val_score\n",
    "cv = KFold(n_splits=3, shuffle=True, random_state=RANDOM_STATE)\n",
    "rf_cv_scores = cross_val_score(rf, X_proc, y_enc, cv=cv, scoring='accuracy', n_jobs=-1)\n",
    "print('RF 3-fold CV accuracy mean:', float(np.mean(rf_cv_scores)))\n",
    "print('RF 3-fold CV accuracy per fold:', rf_cv_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9470940",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_description(disease_name):\n",
    "    if description_df.empty:\n",
    "        return 'description not available (file missing)'\n",
    "    cols = [c.lower() for c in description_df.columns]\n",
    "    if 'disease' in cols and 'description' in cols:\n",
    "        row = description_df[description_df.iloc[:, cols.index('disease')] == disease_name]\n",
    "        if not row.empty:\n",
    "            return row.iloc[0, cols.index('description')]\n",
    "    for _, r in description_df.iterrows():\n",
    "        if disease_name in r.astype(str).values:\n",
    "            for val in r.astype(str).values:\n",
    "                if val and val.lower() != 'nan' and disease_name.lower() not in val.lower():\n",
    "                    return val\n",
    "    return 'description not available for this disease'\n",
    "\n",
    "def get_list_from_df(df, disease_name):\n",
    "    if df.empty:\n",
    "        return []\n",
    "    cols = [c.lower() for c in df.columns]\n",
    "    if 'disease' in cols:\n",
    "        idx = cols.index('disease')\n",
    "        row = df[df.iloc[:, idx] == disease_name]\n",
    "        if not row.empty:\n",
    "            vals = row.iloc[0].drop(row.columns[idx]).dropna().astype(str).tolist()\n",
    "            return vals\n",
    "    for _, r in df.iterrows():\n",
    "        if disease_name in r.astype(str).values:\n",
    "            vals = [v for v in r.astype(str).values if v and v.lower() != 'nan' and disease_name.lower() not in v.lower()]\n",
    "            return vals\n",
    "    return []\n",
    "\n",
    "def get_recommendations_for_disease(disease_name):\n",
    "    desc = get_description(disease_name)\n",
    "    precautions = get_list_from_df(precautions_df, disease_name)\n",
    "    workouts = get_list_from_df(workout_df, disease_name)\n",
    "    meds = get_list_from_df(medications_df, disease_name)\n",
    "    diets = get_list_from_df(diets_df, disease_name)\n",
    "    return {\n",
    "        'disease': disease_name,\n",
    "        'description': desc,\n",
    "        'precautions': precautions,\n",
    "        'workouts': workouts,\n",
    "        'medications': meds,\n",
    "        'diets': diets\n",
    "    }\n",
    "print('recommendation helpers ready')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ac3c9f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def predict_topk_and_recommend(symptoms, top_k=5):\n",
    "    X_row = np.zeros((1, X_proc.shape[1]), dtype=float)\n",
    "    col_index = {c: i for i, c in enumerate(X_proc.columns)}\n",
    "    if isinstance(symptoms, dict):\n",
    "        for name, val in symptoms.items():\n",
    "            idx = col_index.get(name)\n",
    "            if idx is not None and val:\n",
    "                X_row[0, idx] = 1.0\n",
    "    elif isinstance(symptoms, list):\n",
    "        for name in symptoms:\n",
    "            idx = col_index.get(name)\n",
    "            if idx is not None:\n",
    "                X_row[0, idx] = 1.0\n",
    "    else:\n",
    "        raise ValueError('symptoms must be list or dict')\n",
    "\n",
    "    model = None\n",
    "    for m in [globals().get('model_rf_tuned'), globals().get('voting_clf_soft'), globals().get('voting_clf_hard'), globals().get('rf')]:\n",
    "        if m is not None and hasattr(m, 'predict_proba'):\n",
    "            model = m\n",
    "            break\n",
    "    if model is None:\n",
    "        raise RuntimeError('no suitable model with predict_proba found')\n",
    "\n",
    "    probs = model.predict_proba(X_row)[0]\n",
    "    top_idx = np.argsort(probs)[::-1][:top_k]\n",
    "    classes = getattr(label_encoder_y, 'classes_', None)\n",
    "    if classes is None:\n",
    "        raise RuntimeError('label encoder not available')\n",
    "    topk = [(str(classes[i]), float(probs[i])) for i in top_idx]\n",
    "    predicted = str(classes[top_idx[0]])\n",
    "\n",
    "    reco = full_recommendation(predicted)\n",
    "    return {'predicted': predicted, 'topk': topk, 'recommendation': reco}\n",
    "\n",
    "print('prediction function ready')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d63e776",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_symptoms = list(X_proc.columns[:5])\n",
    "print('sample symptoms:', sample_symptoms)\n",
    "res = predict_topk_and_recommend(sample_symptoms, top_k=3)\n",
    "import pprint; pprint.pprint(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b56b8cdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, joblib\n",
    "ARTIFACTS_DIR = 'artifacts'\n",
    "os.makedirs(ARTIFACTS_DIR, exist_ok=True)\n",
    "artifacts = {}\n",
    "for name in ['dt','rf','svm','xgb','voting','stack']:\n",
    "    if name in globals() and globals()[name] is not None:\n",
    "        try:\n",
    "            joblib.dump(globals()[name], os.path.join(ARTIFACTS_DIR, f'{name}.pkl'))\n",
    "            artifacts[name] = f'{name}.pkl'\n",
    "        except Exception as e:\n",
    "            print(f'save {name} skipped:', e)\n",
    "try:\n",
    "    if 'label_encoder_y' in globals():\n",
    "        joblib.dump(label_encoder_y, os.path.join(ARTIFACTS_DIR, 'label_encoder_y.pkl'))\n",
    "        artifacts['label_encoder_y'] = 'label_encoder_y.pkl'\n",
    "except Exception as e:\n",
    "    print('save label_encoder_y skipped:', e)\n",
    "print('artifacts (duplicate saver) wrote:', artifacts)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a4a08ea",
   "metadata": {},
   "source": [
    "## notes\n",
    "- paths use local project files (no colab drive).\n",
    "- shap/xgboost sections are optional (guarded).\n",
    "- we can refine preprocessing once you share exact column semantics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6a514d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, pandas as pd\n",
    "FALLBACK_TRAIN = os.path.join('data', 'dataset', 'trainings.csv')\n",
    "DATA_TRAIN = DATA_TRAIN if 'DATA_TRAIN' in globals() else FALLBACK_TRAIN\n",
    "if not os.path.exists(DATA_TRAIN) and os.path.exists(FALLBACK_TRAIN):\n",
    "    print('Training.csv not found; using fallback:', FALLBACK_TRAIN)\n",
    "    DATA_TRAIN = FALLBACK_TRAIN\n",
    "try:\n",
    "    dataset_train = pd.read_csv(DATA_TRAIN)\n",
    "except UnicodeDecodeError:\n",
    "    dataset_train = pd.read_csv(DATA_TRAIN, encoding='latin1')\n",
    "print('loaded train shape:', dataset_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28af32f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = dataset_train.drop(columns=[dataset_train.columns[-1]])\n",
    "y = dataset_train.iloc[:, -1]\n",
    "print('X shape:', X.shape, 'y shape:', y.shape)\n",
    "\n",
    "X_proc = X.copy()\n",
    "for col in X_proc.columns:\n",
    "    if X_proc[col].dtype == 'object':\n",
    "        X_proc[col] = X_proc[col].astype(str).str.strip().str.lower().replace({'yes':1, 'no':0, 'y':1, 'n':0})\n",
    "    X_proc[col] = pd.to_numeric(X_proc[col], errors='ignore')\n",
    "X_proc = X_proc.fillna(0).astype(float)\n",
    "\n",
    "le = LabelEncoder()\n",
    "y_enc = le.fit_transform(y)\n",
    "print('classes:', list(le.classes_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38855146",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "class_counts = np.bincount(y_enc)\n",
    "strat = y_enc if np.min(class_counts) >= 2 else None\n",
    "if strat is None:\n",
    "    print('note: disabling stratify due to singleton classes')\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X_proc, y_enc, test_size=TEST_SIZE, stratify=strat, random_state=RANDOM_STATE\n",
    ")\n",
    "print('train:', X_train.shape, 'test:', X_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53242069",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('training decision tree...')\n",
    "dt.fit(X_train, y_train)\n",
    "print('training random forest...')\n",
    "rf.fit(X_train, y_train)\n",
    "print('training svm...')\n",
    "svm.fit(X_train, y_train)\n",
    "if 'xgb' in globals() and xgb is not None:\n",
    "    print('training xgboost...')\n",
    "    try:\n",
    "        xgb.fit(X_train, y_train)\n",
    "    except Exception as e:\n",
    "        print('xgb training skipped:', e)\n",
    "print('base models trained')\n",
    "\n",
    "models = {'decision tree': dt, 'random forest': rf, 'svm': svm}\n",
    "if 'xgb' in globals() and xgb is not None:\n",
    "    models['xgb'] = xgb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "758db70f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "baseline_rf = rf\n",
    "tst_pred = baseline_rf.predict(X_test)\n",
    "print('baseline rf accuracy:', accuracy_score(y_test, tst_pred))\n",
    "print(classification_report(y_test, tst_pred, zero_division=0)[:1000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48b2f543",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import KFold, GridSearchCV\n",
    "from sklearn.metrics import make_scorer, f1_score\n",
    "\n",
    "rf_base = RandomForestClassifier(random_state=RANDOM_STATE, n_jobs=-1)\n",
    "param_grid = {\n",
    "    'n_estimators': [200, 400],\n",
    "    'max_depth': [None, 20],\n",
    "}\n",
    "cv = KFold(n_splits=3, shuffle=True, random_state=RANDOM_STATE)\n",
    "scorer = make_scorer(f1_score, average='macro')\n",
    "grid = GridSearchCV(\n",
    "    estimator=rf_base,\n",
    "    param_grid=param_grid,\n",
    "    scoring=scorer,\n",
    "    cv=cv,\n",
    "    n_jobs=-1,\n",
    "    verbose=0\n",
    ")\n",
    "try:\n",
    "    grid.fit(X_train, y_train)\n",
    "    model_rf_tuned = grid.best_estimator_\n",
    "    print('best params:', grid.best_params_)\n",
    "    print('best cv macro f1:', grid.best_score_)\n",
    "except Exception as e:\n",
    "    model_rf_tuned = rf\n",
    "    print('tuning skipped, using baseline RF:', e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d16b9d94",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import ConfusionMatrixDisplay\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "pred_base = rf.predict(X_test)\n",
    "pred_tuned = model_rf_tuned.predict(X_test) if 'model_rf_tuned' in globals() else rf.predict(X_test)\n",
    "\n",
    "from sklearn.metrics import accuracy_score, f1_score, confusion_matrix\n",
    "acc_base = accuracy_score(y_test, pred_base)\n",
    "acc_tuned = accuracy_score(y_test, pred_tuned)\n",
    "f1_b = f1_score(y_test, pred_base, average='macro', zero_division=0)\n",
    "f1_t = f1_score(y_test, pred_tuned, average='macro', zero_division=0)\n",
    "print('baseline rf -> acc:', acc_base, 'macro f1:', f1_b)\n",
    "print('tuned rf   -> acc:', acc_tuned, 'macro f1:', f1_t)\n",
    "\n",
    "cm_base = confusion_matrix(y_test, pred_base)\n",
    "cm_tuned = confusion_matrix(y_test, pred_tuned)\n",
    "\n",
    "fig, ax = plt.subplots(1, 2, figsize=(14, 6))\n",
    "ConfusionMatrixDisplay(confusion_matrix=cm_base).plot(values_format='d', ax=ax[0])\n",
    "ax[0].set_title('baseline rf')\n",
    "ConfusionMatrixDisplay(confusion_matrix=cm_tuned).plot(values_format='d', ax=ax[1])\n",
    "ax[1].set_title('tuned rf')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bc99ee9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import VotingClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "voting_soft = VotingClassifier(estimators=[('rf', rf), ('dt', dt), ('svm', svm)], voting='soft')\n",
    "voting_soft.fit(X_train, y_train)\n",
    "print('voting soft acc:', accuracy_score(y_test, voting_soft.predict(X_test)))\n",
    "\n",
    "voting_hard = VotingClassifier(estimators=[('rf', rf), ('dt', dt), ('svm', svm)], voting='hard')\n",
    "voting_hard.fit(X_train, y_train)\n",
    "print('voting hard acc:', accuracy_score(y_test, voting_hard.predict(X_test)))\n",
    "\n",
    "class_counts_train = np.bincount(y_train)\n",
    "if (class_counts_train < 2).any():\n",
    "    print('stacking skipped due to singleton classes for CV')\n",
    "else:\n",
    "    cv = StratifiedKFold(n_splits=3, shuffle=True, random_state=RANDOM_STATE)\n",
    "    base_estimators = [('rf', rf), ('dt', dt)]\n",
    "    if 'xgb' in globals() and xgb is not None:\n",
    "        base_estimators.append(('xgb', xgb))\n",
    "    stack = StackingClassifier(estimators=base_estimators, final_estimator=LogisticRegression(max_iter=1000), cv=cv, n_jobs=-1)\n",
    "    stack.fit(X_train, y_train)\n",
    "    print('stacking acc:', accuracy_score(y_test, stack.predict(X_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22be3f81",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import KFold, cross_val_score\n",
    "from sklearn.metrics import make_scorer, f1_score\n",
    "scorer_f1m = make_scorer(f1_score, average='macro')\n",
    "cv = KFold(n_splits=3, shuffle=True, random_state=RANDOM_STATE)\n",
    "cv_models = {'baseline_rf': rf, 'tuned_rf': model_rf_tuned if 'model_rf_tuned' in globals() else rf, 'voting_soft': voting_soft}\n",
    "for name, m in cv_models.items():\n",
    "    acc = cross_val_score(m, X_proc, y_enc, cv=cv, scoring='accuracy', n_jobs=-1)\n",
    "    f1m = cross_val_score(m, X_proc, y_enc, cv=cv, scoring=scorer_f1m, n_jobs=-1)\n",
    "    print(f\"{name}: acc mean={acc.mean():.4f} std={acc.std():.4f} | f1m mean={f1m.mean():.4f} std={f1m.std():.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "273369fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import KFold, learning_curve\n",
    "\n",
    "def plot_learning_curve_model(model, X, y, title=None):\n",
    "    if title is None:\n",
    "        title = f'learning curve ({type(model).__name__})'\n",
    "    cv = KFold(n_splits=3, shuffle=True, random_state=RANDOM_STATE)\n",
    "    train_sizes, train_scores, test_scores = learning_curve(model, X, y, cv=cv, scoring='accuracy', train_sizes=np.linspace(0.1, 1.0, 5), n_jobs=-1)\n",
    "    train_mean = np.mean(train_scores, axis=1)\n",
    "    test_mean = np.mean(test_scores, axis=1)\n",
    "    plt.figure(figsize=(6,4))\n",
    "    plt.plot(train_sizes, train_mean, 'o-', label='train')\n",
    "    plt.plot(train_sizes, test_mean, 'o-', label='cv')\n",
    "    plt.title(title)\n",
    "    plt.xlabel('training samples')\n",
    "    plt.ylabel('accuracy')\n",
    "    plt.legend(); plt.tight_layout(); plt.show()\n",
    "\n",
    "for name, m in {'rf_tuned': model_rf_tuned if 'model_rf_tuned' in globals() else rf, 'voting_soft': voting_soft}.items():\n",
    "    plot_learning_curve_model(m, X_train, y_train, title=f'learning curve - {name}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0657186",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import label_binarize\n",
    "def plot_multiclass_roc_model(model, X_test, y_test, title=None):\n",
    "    classes = np.unique(y_test)\n",
    "    n_classes = len(classes)\n",
    "    y_test_b = label_binarize(y_test, classes=classes)\n",
    "    if hasattr(model, 'predict_proba'):\n",
    "        y_score = model.predict_proba(X_test)\n",
    "    else:\n",
    "        y_score = model.decision_function(X_test)\n",
    "    plt.figure(figsize=(8,6))\n",
    "    for i in range(n_classes):\n",
    "        fpr, tpr, _ = roc_curve(y_test_b[:, i], y_score[:, i])\n",
    "        roc_auc = auc(fpr, tpr)\n",
    "        plt.plot(fpr, tpr, lw=2, label=f'{le.classes_[i]} (auc = {roc_auc:.2f})')\n",
    "    plt.plot([0,1],[0,1],'k--')\n",
    "    plt.xlabel('false positive rate')\n",
    "    plt.ylabel('true positive rate')\n",
    "    plt.title(title or f'multiclass roc (one-vs-rest) - {type(model).__name__}')\n",
    "    plt.legend(loc='lower right', fontsize='small')\n",
    "    plt.grid(True)\n",
    "    plt.show()\n",
    "\n",
    "for name, m in {'rf_tuned': rf, 'voting_soft': voting_soft}.items():\n",
    "    plot_multiclass_roc_model(m, X_test, y_test, title=f'roc-auc - {name}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c699d6ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "if HAS_SHAP and HAS_XGB and xgb is not None:\n",
    "    print('computing shap treeexplainer for xgboost...')\n",
    "    explainer_xgb = shap.TreeExplainer(xgb)\n",
    "    sample = X_test.sample(n=min(200, X_test.shape[0]), random_state=RANDOM_STATE)\n",
    "    shap_values_xgb = explainer_xgb.shap_values(sample)\n",
    "    try:\n",
    "        shap.summary_plot(shap_values_xgb, sample, plot_type='bar')\n",
    "        shap.summary_plot(shap_values_xgb, sample)\n",
    "    except Exception as e:\n",
    "        print('could not render shap plots:', e)\n",
    "else:\n",
    "    print('shap/xgb not available; skipping treeexplainer')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e353dff",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_disease(model, symptoms_list):\n",
    "    row = [1.0 if col in symptoms_list else 0.0 for col in X_proc.columns]\n",
    "    X_row = pd.DataFrame([row], columns=X_proc.columns]\n",
    "    pred = model.predict(X_row)[0]\n",
    "    return le.inverse_transform([pred])[0]\n",
    "\n",
    "def predict_topk(model, symptoms_list, top_k=TOP_K):\n",
    "    row = [1.0 if col in symptoms_list else 0.0 for col in X_proc.columns]\n",
    "    X_row = pd.DataFrame([row], columns=X_proc.columns]\n",
    "    if hasattr(model, 'predict_proba'):\n",
    "        probs = model.predict_proba(X_row)[0]\n",
    "    else:\n",
    "        probs = stack.predict_proba(X_row)[0]\n",
    "    top_idx = np.argsort(probs)[::-1][:top_k]\n",
    "    return [(le.classes_[i], float(probs[i])) for i in top_idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf2e0640",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_description(disease_name):\n",
    "    if description_df.empty:\n",
    "        return 'description not available (file missing)'\n",
    "    cols = [c.lower() for c in description_df.columns]\n",
    "    if 'disease' in cols and 'description' in cols:\n",
    "        row = description_df[description_df.iloc[:, cols.index('disease')] == disease_name]\n",
    "        if not row.empty:\n",
    "            return row.iloc[0, cols.index('description')]\n",
    "    for _, r in description_df.iterrows():\n",
    "        if disease_name in r.astype(str).values:\n",
    "            for val in r.astype(str).values:\n",
    "                if val and val.lower() != 'nan' and disease_name.lower() not in val.lower():\n",
    "                    return val\n",
    "    return 'description not available for this disease'\n",
    "\n",
    "def get_list_from_df(df, disease_name):\n",
    "    if df.empty:\n",
    "        return []\n",
    "    cols = [c.lower() for c in df.columns]\n",
    "    if 'disease' in cols:\n",
    "        idx = cols.index('disease')\n",
    "        row = df[df.iloc[:, idx] == disease_name]\n",
    "        if not row.empty:\n",
    "            vals = row.iloc[0].drop(row.columns[idx]).dropna().astype(str).tolist()\n",
    "            return vals\n",
    "    for _, r in df.iterrows():\n",
    "        if disease_name in r.astype(str).values:\n",
    "            vals = [v for v in r.astype(str).values if v and v.lower() != 'nan' and disease_name.lower() not in v.lower()]\n",
    "            return vals\n",
    "    return []\n",
    "\n",
    "def full_recommendation(disease_name):\n",
    "    return {\n",
    "        'disease': disease_name,\n",
    "        'description': get_description(disease_name),\n",
    "        'precautions': get_list_from_df(precautions_df, disease_name),\n",
    "        'workouts': get_list_from_df(workout_df, disease_name),\n",
    "        'medications': get_list_from_df(medications_df, disease_name),\n",
    "        'diets': get_list_from_df(diets_df, disease_name)\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b18532e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "def _safe_read_csv(path):\n",
    "    try:\n",
    "        if os.path.exists(path):\n",
    "            return pd.read_csv(path)\n",
    "    except Exception:\n",
    "        try:\n",
    "            return pd.read_csv(path, encoding='latin1')\n",
    "        except Exception:\n",
    "            pass\n",
    "    return pd.DataFrame()\n",
    "\n",
    "description_df = _safe_read_csv('description.csv')\n",
    "precautions_df = _safe_read_csv('precautions_df.csv')\n",
    "workout_df = _safe_read_csv('workout_df.csv')\n",
    "medications_df = _safe_read_csv('medications.csv')\n",
    "diets_df = _safe_read_csv('diets.csv')\n",
    "print('recommendation CSVs loaded:', {\n",
    "    'description': not description_df.empty,\n",
    "    'precautions': not precautions_df.empty,\n",
    "    'workout': not workout_df.empty,\n",
    "    'medications': not medications_df.empty,\n",
    "    'diets': not diets_df.empty,\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98605681",
   "metadata": {},
   "outputs": [],
   "source": [
    "row = X_test.iloc[[0]] if 'X_test' in globals() and hasattr(X_test, 'iloc') and len(X_test) > 0 else X.iloc[[0]]\n",
    "true_label = y_test[0] if 'y_test' in globals() and hasattr(y_test, 'shape') and y_test.shape[0] > 0 else y.iloc[0]\n",
    "\n",
    "symptoms_from_row = [c for c, v in zip(X_proc.columns, row.iloc[0].values) if v > 0]\n",
    "print('symptoms from row (first 10):', symptoms_from_row[:10])\n",
    "res = predict_topk_and_recommend(symptoms_from_row, top_k=5)\n",
    "print('true label:', true_label)\n",
    "print('predicted:', res['predicted'])\n",
    "print('top-5:', res['topk'])\n",
    "print('recommendation:', res['recommendation'])\n",
    "\n",
    "if 'xgb' in globals() and HAS_SHAP:\n",
    "    try:\n",
    "        explainer = shap.TreeExplainer(xgb)\n",
    "        shap_values = explainer.shap_values(row)\n",
    "        shap.summary_plot(shap_values, row, plot_type='bar')\n",
    "    except Exception as e:\n",
    "        print('shap plotting skipped:', e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "080aef1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, json, joblib\n",
    "\n",
    "ARTIFACTS_DIR = 'artifacts'\n",
    "os.makedirs(ARTIFACTS_DIR, exist_ok=True)\n",
    "\n",
    "artifacts = {}\n",
    "try:\n",
    "    if 'rf' in globals():\n",
    "        joblib.dump(rf, os.path.join(ARTIFACTS_DIR, 'model_rf_baseline.pkl'))\n",
    "        artifacts['model_rf_baseline'] = 'model_rf_baseline.pkl'\n",
    "except Exception as e:\n",
    "    print('baseline rf save skipped:', e)\n",
    "\n",
    "try:\n",
    "    if 'model_rf_tuned' in globals():\n",
    "        joblib.dump(model_rf_tuned, os.path.join(ARTIFACTS_DIR, 'model_rf_tuned.pkl'))\n",
    "        artifacts['model_rf_tuned'] = 'model_rf_tuned.pkl'\n",
    "except Exception as e:\n",
    "    print('tuned rf save skipped:', e)\n",
    "\n",
    "try:\n",
    "    if 'voting_clf_soft' in globals():\n",
    "        joblib.dump(voting_clf_soft, os.path.join(ARTIFACTS_DIR, 'voting_clf_soft.pkl'))\n",
    "        artifacts['voting_clf_soft'] = 'voting_clf_soft.pkl'\n",
    "    if 'voting_clf_hard' in globals():\n",
    "        joblib.dump(voting_clf_hard, os.path.join(ARTIFACTS_DIR, 'voting_clf_hard.pkl'))\n",
    "        artifacts['voting_clf_hard'] = 'voting_clf_hard.pkl'\n",
    "    if 'voting' in globals():\n",
    "        joblib.dump(voting, os.path.join(ARTIFACTS_DIR, 'voting.pkl'))\n",
    "        artifacts['voting'] = 'voting.pkl'\n",
    "except Exception as e:\n",
    "    print('voting save skipped:', e)\n",
    "\n",
    "try:\n",
    "    if 'stack' in globals():\n",
    "        joblib.dump(stack, os.path.join(ARTIFACTS_DIR, 'stacking_clf.pkl'))\n",
    "        artifacts['stacking_clf'] = 'stacking_clf.pkl'\n",
    "except Exception as e:\n",
    "    print('stacking save skipped:', e)\n",
    "\n",
    "try:\n",
    "    joblib.dump(label_encoder_y, os.path.join(ARTIFACTS_DIR, 'label_encoder_y.pkl'))\n",
    "    artifacts['label_encoder_y'] = 'label_encoder_y.pkl'\n",
    "except Exception as e:\n",
    "    print('label encoder save skipped:', e)\n",
    "\n",
    "try:\n",
    "    feature_cols = list(X_proc.columns)\n",
    "    with open(os.path.join(ARTIFACTS_DIR, 'feature_cols.json'), 'w') as f:\n",
    "        json.dump(feature_cols, f)\n",
    "    artifacts['feature_cols'] = 'feature_cols.json'\n",
    "except Exception as e:\n",
    "    print('feature cols save skipped:', e)\n",
    "\n",
    "try:\n",
    "    with open(os.path.join(ARTIFACTS_DIR, 'artifacts_manifest.json'), 'w') as f:\n",
    "        json.dump(artifacts, f, indent=2)\n",
    "    print('saved artifacts:', artifacts)\n",
    "except Exception as e:\n",
    "    print('artifacts manifest save skipped:', e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab6ba1a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd, numpy as np\n",
    "SYMPTOM_COLS = [c for c in df.columns if c != 'Prognosis']\n",
    "presence_matrix = (df[SYMPTOM_COLS].astype(str).apply(lambda col: col.str.strip().str.lower())\n",
    "                   .replace({'nan':'', 'none':'', '': ''})\n",
    "                   .apply(lambda col: (col != '').astype(int)))\n",
    "print('presence_matrix shape:', presence_matrix.shape)\n",
    "print('avg symptoms per disease:', presence_matrix.sum(axis=1).mean())\n",
    "prototype_labels = df['Prognosis'].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8639cacc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "proto_array = presence_matrix.values.astype(float)\n",
    "row_norms = np.linalg.norm(proto_array, axis=1)\n",
    "row_norms[row_norms == 0] = 1.0\n",
    "proto_norm = proto_array / row_norms[:, None]\n",
    "\n",
    "symptom_index = {c: i for i, c in enumerate(SYMPTOM_COLS)}\n",
    "\n",
    "def build_input_vector(symptoms):\n",
    "    vec = np.zeros(len(SYMPTOM_COLS), dtype=float)\n",
    "    if isinstance(symptoms, dict):\n",
    "        for name, val in symptoms.items():\n",
    "            idx = symptom_index.get(name)\n",
    "            if idx is not None and val:\n",
    "                vec[idx] = 1.0\n",
    "    elif isinstance(symptoms, list):\n",
    "        for name in symptoms:\n",
    "            idx = symptom_index.get(name)\n",
    "            if idx is not None:\n",
    "                vec[idx] = 1.0\n",
    "    else:\n",
    "        raise ValueError('symptoms must be list or dict')\n",
    "    n = np.linalg.norm(vec)\n",
    "    if n > 0: vec = vec / n\n",
    "    return vec.reshape(1, -1)\n",
    "\n",
    "def retrieve_topk_similarity(symptoms, k=5):\n",
    "    q = build_input_vector(symptoms)\n",
    "    sims = (proto_norm @ q.T).ravel()\n",
    "    top_idx = np.argsort(sims)[::-1][:k]\n",
    "    results = [(prototype_labels[i], float(sims[i])) for i in top_idx]\n",
    "    return results\n",
    "\n",
    "print('similarity retrieval ready')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a768cee",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "random.seed(RANDOM_STATE)\n",
    "\n",
    "def evaluate_similarity(mask_frac=0.5, ks=(1,3,5,10)):\n",
    "    hits = {k: 0 for k in ks}\n",
    "    total = len(prototype_labels)\n",
    "    for i, label in enumerate(prototype_labels):\n",
    "        symptom_presence = presence_matrix.iloc[i]\n",
    "        active = [SYMPTOM_COLS[j] for j, v in enumerate(symptom_presence.values) if v == 1]\n",
    "        if not active:\n",
    "            continue\n",
    "        keep_n = max(1, int(len(active)*mask_frac))\n",
    "        sampled = random.sample(active, keep_n)\n",
    "        topk = retrieve_topk_similarity(sampled, k=max(ks))\n",
    "        predicted_labels = [t[0] for t in topk]\n",
    "        for k in ks:\n",
    "            if label in predicted_labels[:k]:\n",
    "                hits[k] += 1\n",
    "    metrics = {f'hit@{k}': hits[k]/total for k in ks}\n",
    "    return metrics\n",
    "\n",
    "metrics = evaluate_similarity()\n",
    "print('similarity evaluation metrics:', metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00ca2395",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_with_similarity(symptoms, top_k=5):\n",
    "    topk = retrieve_topk_similarity(symptoms, k=top_k)\n",
    "    best_label = topk[0][0] if topk else None\n",
    "    reco = full_recommendation(best_label) if best_label else {}\n",
    "    return {'topk': topk, 'predicted': best_label, 'recommendation': reco}\n",
    "\n",
    "sample_symptoms_similarity = [SYMPTOM_COLS[i] for i in range(0, min(10, len(SYMPTOM_COLS)))]\n",
    "print('demo symptoms (first 10 cols):', sample_symptoms_similarity)\n",
    "print(predict_with_similarity(sample_symptoms_similarity, top_k=5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5bfd3e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, json, joblib\n",
    "SIM_ART_DIR = 'artifacts'\n",
    "os.makedirs(SIM_ART_DIR, exist_ok=True)\n",
    "joblib.dump(presence_matrix, os.path.join(SIM_ART_DIR, 'presence_matrix.pkl'))\n",
    "with open(os.path.join(SIM_ART_DIR, 'prototype_labels.json'), 'w') as f:\n",
    "    json.dump(prototype_labels, f)\n",
    "with open(os.path.join(SIM_ART_DIR, 'symptom_columns.json'), 'w') as f:\n",
    "    json.dump(SYMPTOM_COLS, f)\n",
    "print('saved similarity artifacts: presence_matrix.pkl, prototype_labels.json, symptom_columns.json')"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
