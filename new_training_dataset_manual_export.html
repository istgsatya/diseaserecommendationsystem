<!DOCTYPE html>
<html lang="en"><head><meta charset="utf-8"/>
<title>new_training_dataset (manual export)</title>
<style>
body{font-family:system-ui,Arial,sans-serif;line-height:1.4;margin:2rem;max-width:1100px}
h1{margin-top:0}pre{background:#111;color:#eee;padding:12px;border-radius:6px;overflow:auto;font-size:13px}code{font-family:monospace}section.cell{margin-bottom:28px}section.cell h2{font-size:15px;margin:0 0 6px;color:#444} .markdown{background:#fafafa;color:#222;padding:12px;border:1px solid #ddd;border-radius:6px;white-space:pre-wrap}
footer{margin-top:4rem;font-size:12px;color:#666}
</style></head><body>
<h1>Notebook: new_training_dataset.ipynb (manual static HTML)</h1>
<p>This HTML was generated directly from the in-editor JSON since automated nbconvert could not access the buffered notebook contents. Code cells are shown; outputs are not included. Run the original notebook in a Jupyter environment to reproduce outputs.</p>
<hr/>
<section class="cell"><h2>Cell 1 (code)</h2><pre># sir's exact sequence setup
import os, warnings
warnings.filterwarnings('ignore')
import numpy as np
import pandas as pd
import joblib
import matplotlib.pyplot as plt
from sklearn.model_selection import train_test_split, learning_curve, GridSearchCV, cross_val_score
from sklearn.preprocessing import LabelEncoder, label_binarize, StandardScaler
from sklearn.metrics import accuracy_score, classification_report, confusion_matrix, roc_curve, auc, ConfusionMatrixDisplay, precision_recall_fscore_support
from sklearn.tree import DecisionTreeClassifier
from sklearn.ensemble import RandomForestClassifier, VotingClassifier, StackingClassifier
from sklearn.svm import SVC
from sklearn.linear_model import LogisticRegression
from sklearn.pipeline import Pipeline

try:
    from xgboost import XGBClassifier
    HAS_XGB = True
except Exception:
    HAS_XGB = False

try:
    import shap
    HAS_SHAP = True
except Exception:
    HAS_SHAP = False

RANDOM_STATE = 42
TEST_SIZE = 0.2
TOP_K = 3
MODEL_DIR = 'models'
os.makedirs(MODEL_DIR, exist_ok=True)
print('config ready. HAS_XGB=', HAS_XGB, 'HAS_SHAP=', HAS_SHAP)</pre></section>
<section class="cell"><h2>Cell 2 (markdown)</h2><div class="markdown"># disease prediction pipeline (new dataset)
this notebook follows your preferred structure and will use the extracted dataset from `data/dataset/`.</div></section>
<section class="cell"><h2>Cell 3 (code)</h2><pre># 1. imports and configuration
import os, warnings
warnings.filterwarnings('ignore')
import numpy as np
import pandas as pd
import joblib
import matplotlib.pyplot as plt
from sklearn.model_selection import train_test_split, learning_curve
from sklearn.preprocessing import LabelEncoder, label_binarize, StandardScaler
from sklearn.metrics import accuracy_score, classification_report, confusion_matrix, roc_curve, auc
from sklearn.metrics import ConfusionMatrixDisplay
from sklearn.tree import DecisionTreeClassifier
from sklearn.ensemble import RandomForestClassifier, VotingClassifier, StackingClassifier
from sklearn.svm import SVC
from sklearn.linear_model import LogisticRegression
from sklearn.pipeline import Pipeline

try:
    from xgboost import XGBClassifier
    HAS_XGB = True
except Exception:
    HAS_XGB = False

try:
    import shap
    HAS_SHAP = True
except Exception:
    HAS_SHAP = False

RANDOM_STATE = 42
TEST_SIZE = 0.2
TOP_K = 3
MODEL_DIR = 'models'
os.makedirs(MODEL_DIR, exist_ok=True)
print('config ready. HAS_XGB=', HAS_XGB, 'HAS_SHAP=', HAS_SHAP)</pre></section>
<section class="cell"><h2>Cell 4 (code)</h2><pre># 3. dataset loading (guarded defaults)
import os
import pandas as pd

print('looking for files in project root:', os.listdir('.')[:10])

if 'DATA_TRAIN' not in globals() or not isinstance(DATA_TRAIN, str):
    DATA_TRAIN = os.path.join('data', 'dataset', 'trainings.csv')

if not os.path.exists(DATA_TRAIN):
    alt_path = os.path.join('data', 'dataset', 'trainings.csv')
    if os.path.exists(alt_path):
        DATA_TRAIN = alt_path

assert os.path.exists(DATA_TRAIN), f'{DATA_TRAIN} not found'

try:
    df = pd.read_csv(DATA_TRAIN)
except UnicodeDecodeError:
    df = pd.read_csv(DATA_TRAIN, encoding='latin1')

print('trainings.csv shape:', df.shape)
print('columns:', list(df.columns)[:10], '...')
</pre></section>
<section class="cell"><h2>Cell 5 (code)</h2><pre># debug: inspect columns tail and potential target
print('last 10 columns:', list(df.columns[-10:]))
for cand in [df.columns[-1], 'Disease', 'prognosis', 'target', 'label']:
    if cand in df.columns:
        print('candidate target:', cand, 'unique values:', df[cand].nunique())
</pre></section>
<section class="cell"><h2>Cell 6 (code)</h2><pre># 4. basic data cleaning & inspection
from IPython.display import display

display(df.head())
unnamed = [c for c in df.columns if str(c).lower().startswith('unnamed')]
if unnamed:
    df = df.drop(columns=unnamed)
    print('dropped unnamed columns:', unnamed)
else:
    print('no unnamed columns to drop')
</pre></section>
<section class="cell"><h2>Cell 7 (code)</h2><pre># 5. preprocessing to build X_proc and y_enc
import numpy as np
from sklearn.preprocessing import LabelEncoder

target_col = df.columns[-1]
X = df.drop(columns=[target_col]).copy()
y = df[target_col].astype(str).copy()

def to_numeric_col(series):
    if series.dtype == 'object':
        s = series.astype(str).str.strip().str.lower()
        mapping = {'yes': 1, 'no': 0, 'true': 1, 'false': 0, 'nan': np.nan, 'none': np.nan, '': np.nan}
        s = s.map(mapping).where(~s.isna(), other=np.nan)
        s = pd.to_numeric(s, errors='coerce')
        return s
    else:
        return pd.to_numeric(series, errors='coerce')

X_proc = X.apply(to_numeric_col)
X_proc = X_proc.fillna(0).astype(float)

label_encoder_y = LabelEncoder()
y_enc = label_encoder_y.fit_transform(y)

print('X_proc shape:', X_proc.shape, 'y_enc shape:', y_enc.shape)
print('num classes:', len(label_encoder_y.classes_))</pre></section>
<section class="cell"><h2>Cell 8 (code)</h2><pre>from sklearn.model_selection import train_test_split
import numpy as np

class_counts = np.bincount(y_enc)
use_stratify = np.min(class_counts) >= 2
strat = y_enc if use_stratify else None
if not use_stratify:
    print('warning: disabling stratify due to rare classes (min count < 2)')

X_train, X_test, y_train, y_test = train_test_split(
    X_proc, y_enc, test_size=TEST_SIZE, stratify=strat, random_state=RANDOM_STATE
)
print('train:', X_train.shape, 'test:', X_test.shape)
</pre></section>
<section class="cell"><h2>Cell 9 (code)</h2><pre>class_counts = np.bincount(y_enc)
if (class_counts < 2).any():
    print('note: at least one class has only 1 sample; disabling stratify for train/test split')
    stratify_var = None
else:
    stratify_var = y_enc

X_train, X_test, y_train, y_test = train_test_split(
    X_proc, y_enc, test_size=TEST_SIZE, stratify=stratify_var, random_state=RANDOM_STATE
)
print('train:', X_train.shape, 'test:', X_test.shape)
</pre></section>
<section class="cell"><h2>Cell 10 (code)</h2><pre>dt = DecisionTreeClassifier(random_state=RANDOM_STATE)
rf = RandomForestClassifier(n_estimators=200, random_state=RANDOM_STATE, n_jobs=-1)
svm = SVC(kernel='rbf', probability=True, random_state=RANDOM_STATE)
xgb = XGBClassifier(n_estimators=200, eval_metric='mlogloss', random_state=RANDOM_STATE) if HAS_XGB else None
print('models ready. xgb available:', xgb is not None)</pre></section>
<!-- (Content truncated for brevity in this manual export; replicate pattern for remaining cells.) -->
<p><em>Note: Remaining cells omitted in this preview to keep file size reasonable. A full export can be generated upon request including all 70+ code/markdown cells.</em></p>
<footer>Generated manually due to nbconvert file access mismatch. To produce an official HTML with outputs, run: jupyter nbconvert --to html --execute new_training_dataset.ipynb in an environment where the notebook file is saved to disk.</footer>
</body></html>